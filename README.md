# Sensitivity-based-Adversaries

Neural Networks are known to perform well on images but their performance
is affected by adversaries. In simple terms, Adversaries are nothing but the
input images perturbed by adding noise. In order to understand why the neural
networks are so much susceptible to noise, first we need to understand their
behavior. So, I have tried to perform sensitivity analysis for a neural network.
For this research project I have used MNIST data and I have trained a simple
neural network with 2 hidden layers with a dropout, in order to make sure the
network does not overfit. The accuracy of this network comes out to be 98.52%.


Please refer the document-
Sensitivity_based_adversaries to understand the logic of the function.







